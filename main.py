import html
import os
import re
import time
from datetime import datetime
from typing import Dict, List, Optional
import pandas as pd
import requests
from bs4 import BeautifulSoup

# ğŸ”¥ êµ¬ê¸€ì˜ ìµœì‹  ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
from google import genai

# --- ì„¤ì •ë¶€ ---
QUERY = "ë¶€ë™ì‚° ì „ë§"
TARGET_COUNT = 20 
CSV_PATH = "news_data.csv"

# ğŸ›‘ í€„ë¦¬í‹° í•„í„°: ê±°ë¥´ê³  ì‹¶ì€ ì–¸ë¡ ì‚¬ë‚˜ ê¸°ì ì´ë¦„ì„ ë„£ìœ¼ì„¸ìš”.
EXCLUDE_PUBLISHERS = ["ë‚˜ìœì¼ë³´", "ê´‘ê³ ì‹ ë¬¸"] 
EXCLUDE_REPORTERS = ["í™ê¸¸ë™", "ì•„ë¬´ê°œ"]

# ğŸš€ ìš°ë¦¬ê°€ ë¼ˆë¥¼ ë¬»ì„ ìµœì¢… ëª¨ë¸
TARGET_MODEL = "gemini-2.5-flash-lite"

def get_env(name: str) -> str:
    value = os.getenv(name)
    if not value:
        raise EnvironmentError(f"í™˜ê²½ë³€ìˆ˜ {name}ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    return value

def extract_article_metadata(link: str) -> Dict[str, str]:
    metadata = {"publisher": "Unknown", "reporter": "Unknown", "content": ""}
    try:
        resp = requests.get(link, timeout=10, headers={"User-Agent": "Mozilla/5.0"})
        soup = BeautifulSoup(resp.text, "html.parser")
        
        content_node = soup.select_one("article#dic_area") or soup.select_one("#newsct_article") or soup.select_one("#articleBodyContents")
        if content_node:
            metadata["content"] = content_node.get_text(" ", strip=True)[:2500]
            
        pub_meta = soup.select_one("meta[property='og:site_name']")
        if pub_meta:
            metadata["publisher"] = pub_meta.get("content", "Unknown").strip()
            
        reporter_node = soup.select_one(".byline_s") or soup.select_one(".media_end_head_journalist_name")
        if reporter_node:
            metadata["reporter"] = reporter_node.get_text(" ", strip=True).split(' ')[0]
    except:
        pass
    return metadata

def main():
    client_id = get_env("NAVER_CLIENT_ID")
    client_secret = get_env("NAVER_CLIENT_SECRET")
    gemini_api_key = get_env("GEMINI_API_KEY")

    try:
        client = genai.Client(api_key=gemini_api_key)
        print(f"âœ… êµ¬ê¸€ AI ì—°ê²° ì„±ê³µ! [{TARGET_MODEL}] ëª¨ë¸ë¡œ ë‹¬ë¦½ë‹ˆë‹¤ ğŸš—ğŸ’¨")
    except Exception as e:
        print(f"âŒ êµ¬ê¸€ AI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì‹¤íŒ¨: {e}")
        return

    print(f"ğŸš€ '{QUERY}' ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")
    headers = {"X-Naver-Client-Id": client_id, "X-Naver-Client-Secret": client_secret}
    params = {"query": QUERY, "display": 100, "sort": "date"}
    res = requests.get("https://openapi.naver.com/v1/search/news.json", headers=headers, params=params)
    items = res.json().get("items", [])

    analyzed = []
    error_count = 0 

    for item in items:
        if len(analyzed) >= TARGET_COUNT or error_count > 10:
            break
        
        link = item.get("originallink") or item.get("link")
        meta = extract_article_metadata(link)
        
        # í•„í„°ë§ ì‘ë™
        if any(bad_pub in meta['publisher'] for bad_pub in EXCLUDE_PUBLISHERS): continue
        if any(bad_rep in meta['reporter'] for bad_rep in EXCLUDE_REPORTERS): continue

        prompt = f"""ë¶€ë™ì‚° ì „ë¬¸ê°€ë¡œì„œ ì•„ë˜ ê¸°ì‚¬ë¥¼ ë¶„ì„í•´ ì¤˜.
[ì¤‘ìš”] ìš”ì•½ì€ ë°˜ë“œì‹œ 3ë¬¸ì¥(3ì¤„) ì´ë‚´ë¡œ ëë‚´ì•¼ í•´.
ë¶€ë™ì‚°ê³¼ ë¬´ê´€í•œ ê¸°ì‚¬ë©´ "Signal: INVALID"ë¼ê³ ë§Œ ë‹µí•´.

ì œëª©: {item['title']}
ë³¸ë¬¸: {meta['content']}

ë§ˆì§€ë§‰ì— ì•„ë˜ í˜•ì‹ ì¶”ê°€:
Region: ì§€ì—­
Keyword: í‚¤ì›Œë“œ
Signal: (BULL/BEAR/FLAT)
"""

        try:
            # Lite ëª¨ë¸ì´ë¼ í•œë„ ë„‰ë„‰í•˜ì§€ë§Œ ì•ˆì „í•˜ê²Œ 10ì´ˆ ëŒ€ê¸°
            print(f"â³ 10ì´ˆ ëŒ€ê¸° ì¤‘... (í˜„ì¬ {len(analyzed)}/30 ì™„ë£Œ)")
            time.sleep(10) 
            
            response = client.models.generate_content(
                model=TARGET_MODEL,
                contents=prompt
            )
            text = response.text
            
            if "INVALID" in text.upper():
                error_count = 0 
                continue

            signal = "FLAT"
            if "BULL" in text.upper(): signal = "BULL"
            elif "BEAR" in text.upper(): signal = "BEAR"

            analyzed.append({
                "title": re.sub(r"<[^>]+>", "", item['title']),
                "link": link,
                "summary": text.strip(),
                "publisher": meta['publisher'],
                "reporter": meta['reporter'],
                "signal": signal,
                "collected_at": datetime.now().strftime("%Y-%m-%d %H:%M")
            })
            print(f"âœ… ìš”ì•½ ì„±ê³µ: {item['title'][:20]}...")
            error_count = 0 

        except Exception as e:
            print(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
            if "429" in str(e) or "Quota" in str(e):
                print("ğŸš¨ í• ë‹¹ëŸ‰ ì´ˆê³¼. ë‚´ì¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
                break
            error_count += 1
            time.sleep(15) 

    if analyzed:
        pd.DataFrame(analyzed).to_csv(CSV_PATH, index=False, encoding="utf-8-sig")
        print(f"ğŸ‰ ì´ {len(analyzed)}ê±´ ì•ˆì „í•˜ê²Œ ì €ì¥ ì™„ë£Œ!")
    else:
        print("ì €ì¥í•  ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()

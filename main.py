import os
import re
import time
from datetime import datetime
import pandas as pd
import requests
from bs4 import BeautifulSoup
from google import genai

# --- PRO ì„¤ì •ë¶€ ---
QUERY = "ë¶€ë™ì‚° ì „ë§"
TARGET_COUNT = 20  # í•˜ë£¨ í•œë„ ë°©ì–´ë¥¼ ìœ„í•œ 20ê°œ ì„¸íŒ…
CSV_PATH = "news_data.csv"
TARGET_MODEL = "gemini-2.5-flash"  # ì‚¬ìš©ìë‹˜ì´ ì„ íƒí•˜ì‹  2.5 ë²„ì „ ìœ ì§€

def get_env(name: str) -> str:
    return os.getenv(name, "")

def extract_article_metadata(link: str) -> dict:
    metadata = {"publisher": "Unknown", "reporter": "Unknown", "content": ""}
    try:
        resp = requests.get(link, timeout=10, headers={"User-Agent": "Mozilla/5.0"})
        soup = BeautifulSoup(resp.text, "html.parser")
        content_node = soup.select_one("article#dic_area") or soup.select_one("#newsct_article") or soup.select_one("#articleBodyContents")
        if content_node:
            metadata["content"] = content_node.get_text(" ", strip=True)[:2500]
        pub_meta = soup.select_one("meta[property='og:site_name']")
        if pub_meta:
            metadata["publisher"] = pub_meta.get("content", "Unknown").strip()
    except:
        pass
    return metadata

def main():
    client_id = get_env("NAVER_CLIENT_ID")
    client_secret = get_env("NAVER_CLIENT_SECRET")
    api_key = get_env("GEMINI_API_KEY")

    if not api_key:
        print("âŒ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    client = genai.Client(api_key=api_key)
    print(f"ğŸš€ í”„ë¡œë²„ì „ ìˆ˜ì§‘ê¸° ê°€ë™: {TARGET_MODEL}")

    headers = {"X-Naver-Client-Id": client_id, "X-Naver-Client-Secret": client_secret}
    res = requests.get("https://openapi.naver.com/v1/search/news.json", headers=headers, params={"query": QUERY, "display": 100, "sort": "date"})
    items = res.json().get("items", [])

    new_analyzed = []
    error_count = 0 

    for item in items:
        if len(new_analyzed) >= TARGET_COUNT or error_count > 5:
            break
        
        link = item.get("originallink") or item.get("link")
        meta = extract_article_metadata(link)
        
        prompt = f"""ë¶€ë™ì‚° ì „ë¬¸ê°€ë¡œì„œ ì•„ë˜ ê¸°ì‚¬ë¥¼ 3ë¬¸ì¥ ì´ë‚´ë¡œ ìš”ì•½í•´. ì •ì¹˜/ì‚¬ê±´ ê¸°ì‚¬ë©´ "Signal: INVALID"ë¼ê³  ë‹µí•´.
ì œëª©: {item['title']}
ë³¸ë¬¸: {meta['content']}

[í•„ìˆ˜í˜•ì‹]
Region: ì§€ì—­ëª…
Keyword: í•µì‹¬í‚¤ì›Œë“œ
Signal: (BULL/BEAR/FLAT)"""

        try:
            print(f"â³ AI ë¶„ì„ ì¤‘... ({len(new_analyzed)+1}/{TARGET_COUNT})")
            time.sleep(10) # 2.5 ë²„ì „ í•œë„(RPM) ë°©ì–´
            response = client.models.generate_content(model=TARGET_MODEL, contents=prompt)
            text = response.text
            
            if "INVALID" in text.upper(): continue

            signal = "FLAT"
            if "BULL" in text.upper(): signal = "BULL"
            elif "BEAR" in text.upper(): signal = "BEAR"

            new_analyzed.append({
                "title": re.sub(r"<[^>]+>", "", item['title']),
                "link": link,
                "summary": text.strip(),
                "publisher": meta['publisher'],
                "reporter": meta['reporter'],
                "signal": signal,
                "collected_at": datetime.now().strftime("%Y-%m-%d %H:%M")
            })
            print(f"âœ… ì™„ë£Œ: {item['title'][:15]}...")

        except Exception as e:
            print(f"âš ï¸ ì˜¤ë¥˜: {e}")
            if "429" in str(e): break
            error_count += 1

    # ğŸ”¥ [PRO] ì™„ë²½í•œ ë°ì´í„° ëˆ„ì  ë¡œì§
    if new_analyzed:
        new_df = pd.DataFrame(new_analyzed)
        if os.path.exists(CSV_PATH):
            try:
                old_df = pd.read_csv(CSV_PATH)
                combined_df = pd.concat([old_df, new_df], ignore_index=True)
                # ë§í¬(link)ê°€ ê°™ì€ ì¤‘ë³µ ê¸°ì‚¬ëŠ” ìµœì‹  ìˆ˜ì§‘ë³¸ í•˜ë‚˜ë§Œ ë‚¨ê¸°ê³  ì‚­ì œ
                combined_df = combined_df.drop_duplicates(subset=['link'], keep='last')
            except:
                combined_df = new_df
        else:
            combined_df = new_df

        # ìµœì‹  ê¸°ì‚¬ê°€ ìœ„ë¡œ ì˜¤ë„ë¡ ì •ë ¬ í›„ ì €ì¥
        combined_df = combined_df.sort_values(by="collected_at", ascending=False)
        combined_df.to_csv(CSV_PATH, index=False, encoding="utf-8-sig")
        print(f"ğŸ‰ ëˆ„ì  ì €ì¥ ì„±ê³µ! ì´ {len(combined_df)}ê±´ì˜ DBê°€ êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("ì €ì¥í•  ì‹ ê·œ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()

name: Daily Real Estate Signal Scraper

on:
  schedule:
    - cron: '30 23 * * *'
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: real-estate-scrape
  cancel-in-progress: false

jobs:
  scrape-and-commit:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    defaults:
      run:
        shell: bash
        working-directory: ${{ github.workspace }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Verify required files
        run: |
          pwd
          ls -la
          test -f requirements.txt || (echo 'requirements.txt not found in repo root' && find . -maxdepth 3 -name requirements.txt -print && exit 1)
          test -f main.py || (echo 'main.py not found in repo root' && find . -maxdepth 3 -name main.py -print && exit 1)

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run scraper
        env:
          NAVER_CLIENT_ID: ${{ secrets.NAVER_CLIENT_ID }}
          NAVER_CLIENT_SECRET: ${{ secrets.NAVER_CLIENT_SECRET }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: python main.py

      - name: Commit and push news_data.csv
        run: |
          git config user.name 'github-actions[bot]'
          git config user.email '41898282+github-actions[bot]@users.noreply.github.com'

          if [ ! -f news_data.csv ]; then
            echo 'news_data.csv not found; nothing to commit'
            exit 0
          fi

          git add news_data.csv
          if git diff --cached --quiet; then
            echo 'No changes to commit'
            exit 0
          fi

          git commit -m 'chore: update news_data.csv'
          git push
